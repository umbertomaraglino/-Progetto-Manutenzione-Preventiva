{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>Condition</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425149</th>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>1.948734</td>\n",
       "      <td>1.912482</td>\n",
       "      <td>1.904362</td>\n",
       "      <td>1.835654</td>\n",
       "      <td>1.924899</td>\n",
       "      <td>1.857220</td>\n",
       "      <td>1.920020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425150</th>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>1.948823</td>\n",
       "      <td>1.899824</td>\n",
       "      <td>1.884360</td>\n",
       "      <td>1.825497</td>\n",
       "      <td>1.927513</td>\n",
       "      <td>1.846068</td>\n",
       "      <td>1.919081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425151</th>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>1.957784</td>\n",
       "      <td>1.911383</td>\n",
       "      <td>1.893740</td>\n",
       "      <td>1.859805</td>\n",
       "      <td>1.940953</td>\n",
       "      <td>1.861668</td>\n",
       "      <td>1.950562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425152</th>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>1.970451</td>\n",
       "      <td>1.950009</td>\n",
       "      <td>1.945417</td>\n",
       "      <td>1.913911</td>\n",
       "      <td>1.953648</td>\n",
       "      <td>1.835381</td>\n",
       "      <td>1.983321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425153</th>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>1.988895</td>\n",
       "      <td>1.997232</td>\n",
       "      <td>2.003571</td>\n",
       "      <td>1.989339</td>\n",
       "      <td>1.981822</td>\n",
       "      <td>1.888756</td>\n",
       "      <td>1.985784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425154 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Case  Condition        P1        P2        P3        P4        P5  \\\n",
       "0          1          0  2.000000  2.000000  2.000000  2.000000  2.000000   \n",
       "1          1          0  2.000000  2.000000  2.000000  2.000000  2.000000   \n",
       "2          1          0  2.000000  2.000000  2.000000  2.000000  2.000000   \n",
       "3          1          0  2.000000  2.000000  2.000000  2.000000  2.000000   \n",
       "4          1          0  2.000000  2.000000  2.000000  2.000000  2.000000   \n",
       "...      ...        ...       ...       ...       ...       ...       ...   \n",
       "425149   177          2  1.948734  1.912482  1.904362  1.835654  1.924899   \n",
       "425150   177          2  1.948823  1.899824  1.884360  1.825497  1.927513   \n",
       "425151   177          2  1.957784  1.911383  1.893740  1.859805  1.940953   \n",
       "425152   177          2  1.970451  1.950009  1.945417  1.913911  1.953648   \n",
       "425153   177          2  1.988895  1.997232  2.003571  1.989339  1.981822   \n",
       "\n",
       "              P6        P7  \n",
       "0       2.000000  2.000000  \n",
       "1       2.000000  2.000000  \n",
       "2       2.000000  2.000000  \n",
       "3       2.000000  2.000000  \n",
       "4       2.000000  2.000000  \n",
       "...          ...       ...  \n",
       "425149  1.857220  1.920020  \n",
       "425150  1.846068  1.919081  \n",
       "425151  1.861668  1.950562  \n",
       "425152  1.835381  1.983321  \n",
       "425153  1.888756  1.985784  \n",
       "\n",
       "[425154 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VALUTAZIONE STRADA ALTERNATIVA\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_train_finale.csv\")\n",
    "df = df[[\"Case\",\"Condition\",\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "df = pd.concat([df]*2, ignore_index=True)\n",
    "\n",
    "condition_mapping = {'Normal': 0, 'Fault': 1, 'Anomaly': 2}\n",
    "# 0=normal 1=SV e 2=BUBBLE\n",
    "df['Condition'] = df['Condition'].map(condition_mapping)\n",
    "x=df[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "y = df['Condition']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umber\\AppData\\Local\\Temp\\ipykernel_55248\\3147037794.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['Prediction'] = predictions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>178</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>184</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>192</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>197</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>204</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>207</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>216</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>218</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>221</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>222</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case  Prediction\n",
       "0    178           2\n",
       "1    179           1\n",
       "2    180           0\n",
       "3    181           0\n",
       "4    182           0\n",
       "5    183           0\n",
       "6    184          -1\n",
       "7    185           0\n",
       "8    186           2\n",
       "9    187           0\n",
       "10   188           1\n",
       "11   189           0\n",
       "12   190           1\n",
       "13   191           0\n",
       "14   192          -1\n",
       "15   193           2\n",
       "16   194           0\n",
       "17   195           0\n",
       "18   196           2\n",
       "19   197           2\n",
       "20   198           0\n",
       "21   199           0\n",
       "22   200          -1\n",
       "23   201           0\n",
       "24   202           1\n",
       "25   203           0\n",
       "26   204           2\n",
       "27   205           0\n",
       "28   206           0\n",
       "29   207          -1\n",
       "30   208           0\n",
       "31   209           2\n",
       "32   210           0\n",
       "33   211           0\n",
       "34   212           1\n",
       "35   213           0\n",
       "36   214           1\n",
       "37   215           0\n",
       "38   216           2\n",
       "39   217           0\n",
       "40   218          -1\n",
       "41   219           2\n",
       "42   220           0\n",
       "43   221           2\n",
       "44   222          -1\n",
       "45   223           0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALLENAMENTO STRADA ALTERNATIVA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_train_finale.csv\")\n",
    "df = df[[\"Case\",\"Condition\",\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "df = pd.concat([df]*2, ignore_index=True)\n",
    "\n",
    "x_test=pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_test_finale.csv\")\n",
    "test = x_test[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "colonna = x_test[[\"Case\"]]\n",
    "\n",
    "condition_mapping = {'Normal': 0, 'Fault': 1, 'Anomaly': 2}\n",
    "# 0=normal 1=SV e 2=BUBBLE\n",
    "df['Condition'] = df['Condition'].map(condition_mapping)\n",
    "x=df[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "y = df['Condition']\n",
    "\n",
    "model = RandomForestClassifier(max_depth = None, min_samples_leaf = 1, min_samples_split = 2, n_estimators = 200, random_state=42)\n",
    "model.fit(x, y)\n",
    "predictions = model.predict(test)\n",
    "test['Prediction'] = predictions\n",
    "\n",
    "df_unito = pd.concat([colonna, test], axis=1)\n",
    "grouped_data = df_unito.groupby('Case')['Prediction'].apply(lambda x: x.mode().iat[0]).reset_index() # restituisce il valore più frequente (moda)\n",
    "\n",
    "\n",
    "cases_to_exclude = [184, 192, 200, 207, 218, 222]\n",
    "grouped_data.loc[grouped_data['Case'].isin(cases_to_exclude), 'Prediction'] = -1\n",
    "grouped_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "percorso_file_excel = r'C:\\Users\\umber\\Desktop\\tabella.xlsx'\n",
    "\n",
    "grouped_data.to_excel(percorso_file_excel, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umber\\AppData\\Local\\Temp\\ipykernel_18712\\759066464.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['Prediction'] = predictions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>178</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>197</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>204</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>221</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case  Prediction\n",
       "0    178           2\n",
       "1    179           1\n",
       "2    184           1\n",
       "3    186           2\n",
       "4    188           1\n",
       "5    192           1\n",
       "6    193           2\n",
       "7    196           2\n",
       "8    197           2\n",
       "9    200           1\n",
       "10   202           1\n",
       "11   203           1\n",
       "12   204           2\n",
       "13   205           1\n",
       "14   207           1\n",
       "15   209           2\n",
       "16   211           1\n",
       "17   214           1\n",
       "18   215           1\n",
       "19   216           1\n",
       "20   218           1\n",
       "21   219           2\n",
       "22   220           1\n",
       "23   221           2\n",
       "24   222           1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALLENAMENTO SENZA DWT\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_train_finale.csv\")\n",
    "df = df.loc[(df['Case'] >= 106) & (df['Case'] <= 177)]\n",
    "x_test=pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_test_finale.csv\")\n",
    "valori_desiderati = [178, 179, 184, 186, 188, 192, 193, 196, 197, 200, 202, 203, 204, 205, 207, 209, 211, 214, 215, 216, 218, 219, 220 ,221, 222]\n",
    "x_test = x_test[x_test['Case'].isin(valori_desiderati)]\n",
    "test = x_test[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "df = df[[\"Case\",\"Condition\",\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "condition_mapping = {'Fault': 1, 'Anomaly': 2}\n",
    "#0=normal 1=SV e 2=BUBBLE\n",
    "df['Condition'] = df['Condition'].map(condition_mapping)\n",
    "#ALLENAMENTO MODELLO\n",
    "# Creazione di un DataFrame con le features e il target\n",
    "test = x_test[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "colonna = x_test[[\"Case\"]]\n",
    "X=df[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "y = df['Condition']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Creazione e addestramento del modello\n",
    "model = RandomForestClassifier(max_depth = None, min_samples_leaf = 1, min_samples_split = 2, n_estimators = 200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(test)\n",
    "test['Prediction'] = predictions\n",
    "\n",
    "df_unito = pd.concat([colonna, test], axis=1)\n",
    "grouped_data = df_unito.groupby('Case')['Prediction'].apply(lambda x: x.mode().iat[0]).reset_index() # restituisce il valore più frequente (moda)\n",
    "grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>IsolationForest_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>184</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>192</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>207</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>218</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>222</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case  IsolationForest_Prediction\n",
       "6    184                          -1\n",
       "14   192                          -1\n",
       "22   200                          -1\n",
       "29   207                          -1\n",
       "40   218                          -1\n",
       "44   222                          -1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#INDIVIDUAZIONE ANOMALIE\n",
    "import pandas as pd\n",
    "x_train = pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_train_finale.csv\")\n",
    "x_train = x_train[[\"Case\",\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "x_test=pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_test_finale.csv\")\n",
    "x_test= x_test[[\"Case\",\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "model = IsolationForest()\n",
    "model.fit(x_train)\n",
    "predictions = model.predict(x_test)\n",
    "x_test['IsolationForest_Prediction'] = predictions\n",
    "# istanze non normali = -1\n",
    "grouped_data = x_test.groupby('Case')['IsolationForest_Prediction'].apply(lambda x: x.mode().iat[0]).reset_index()\n",
    "filtered_data = grouped_data[grouped_data['IsolationForest_Prediction'] == -1]\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREAZIONE TABELLA TASK 2 UNENDO LE 6 ANOMALIE\n",
    "grouped_data.rename(columns={'Prediction': 'Task2'}, inplace=True)\n",
    "newww = grouped_data[[\"Case\",\"Task2\"]]\n",
    "newww.loc[newww['Case'].isin([184, 192, 200, 207, 218, 222]), 'Task2'] = -1\n",
    "percorso_file_excel = r'C:\\Users\\umber\\Desktop\\tabella_task2.xlsx'\n",
    "\n",
    "newww.to_excel(percorso_file_excel, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punteggi della cross-validation: [0.82804279 0.81006071 0.82120967 0.75488609 0.76037932]\n",
      "Media dei punteggi: 0.7949157152365199\n"
     ]
    }
   ],
   "source": [
    "# VALUTAZIONE SENZA DWT\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "df = pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_train_finale.csv\")\n",
    "df = df.loc[(df['Case'] >= 106) & (df['Case'] <= 177)]\n",
    "x_test=pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_test_finale.csv\")\n",
    "valori_desiderati = [178, 179, 184, 186, 188, 192, 193, 196, 197, 200, 202, 203, 204, 205, 207, 209, 211, 214, 215, 216, 218, 219, 220 ,221, 222]\n",
    "x_test = x_test[x_test['Case'].isin(valori_desiderati)]\n",
    "test = x_test[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "df = df[[\"Case\",\"Condition\",\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "condition_mapping = {'Fault': 1, 'Anomaly': 2}\n",
    "#0=normal 1=SV e 2=BUBBLE\n",
    "df['Condition'] = df['Condition'].map(condition_mapping)\n",
    "#ALLENAMENTO MODELLO\n",
    "# Creazione di un DataFrame con le features e il target\n",
    "test = x_test[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "colonna = x_test[[\"Case\"]]\n",
    "X=df[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "y = df['Condition']\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Esegui la cross-validation con 5 fold\n",
    "scores = cross_val_score(rf_classifier, X, y, cv=5)\n",
    "\n",
    "# Stampiamo i punteggi ottenuti dalla cross-validation\n",
    "print(\"Punteggi della cross-validation:\", scores)\n",
    "\n",
    "# Calcola la media dei punteggi\n",
    "print(\"Media dei punteggi:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pywt\\_multilevel.py:43: UserWarning: Level value of 12 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pywt\\_multilevel.py:43: UserWarning: Level value of 12 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "C:\\Users\\umber\\AppData\\Local\\Temp\\ipykernel_8252\\4142548138.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['Prediction'] = predictions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>178</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>192</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>207</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>222</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case  Prediction\n",
       "0    178           2\n",
       "1    179           1\n",
       "2    184           1\n",
       "3    186           1\n",
       "4    188           1\n",
       "5    192           2\n",
       "6    193           1\n",
       "7    196           2\n",
       "8    197           1\n",
       "9    200           1\n",
       "10   202           1\n",
       "11   203           1\n",
       "12   204           1\n",
       "13   205           1\n",
       "14   207           2\n",
       "15   209           1\n",
       "16   211           1\n",
       "17   214           1\n",
       "18   215           1\n",
       "19   216           1\n",
       "20   218           1\n",
       "21   219           1\n",
       "22   220           1\n",
       "23   221           1\n",
       "24   222           2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALLENAMENTO CON DWT\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pywt import wavedec\n",
    "from sklearn.metrics import classification_report\n",
    "import pywt\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    " \n",
    "df = pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_train_finale.csv\")\n",
    "df = df.loc[(df['Case'] >= 106) & (df['Case'] <= 177)]\n",
    "df = df[[\"Case\",\"Condition\",\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    " \n",
    " \n",
    "x_test=pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_test_finale.csv\")\n",
    "valori_desiderati = [178, 179, 184, 186, 188, 192, 193, 196, 197, 200, 202, 203, 204, 205, 207, 209, 211, 214, 215, 216, 218, 219, 220 ,221, 222]\n",
    "x_test = x_test[x_test['Case'].isin(valori_desiderati)]\n",
    "test = x_test[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "colonna = x_test[[\"Case\"]]\n",
    " \n",
    " \n",
    "condition_mapping = {'Fault': 1, 'Anomaly': 2}\n",
    "df['Condition'] = df['Condition'].map(condition_mapping)\n",
    "X=df[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "y = df['Condition']\n",
    " \n",
    "X_dwt = np.concatenate(pywt.wavedec(X, 'db1',level = 12), axis=-1)\n",
    " \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_dwt)\n",
    " \n",
    "X_dwt_test = np.concatenate(pywt.wavedec(test, 'db1',level = 12), axis=-1)\n",
    " \n",
    "scaler = StandardScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_dwt_test)\n",
    " \n",
    "#x_train_sv, x_test_sv, y_train_sv, y_test_sv = train_test_split(X_train_scaled, y, test_size=0.15)\n",
    "model = RandomForestClassifier(max_depth = None, min_samples_leaf = 1, min_samples_split = 2, n_estimators = 200, random_state=42)\n",
    "model.fit(X_train_scaled, y)\n",
    " \n",
    "# predizioni con dwt\n",
    " \n",
    "predictions = model.predict(X_test_scaled)\n",
    "test['Prediction'] = predictions\n",
    " \n",
    "df_unito = pd.concat([colonna, test], axis=1)\n",
    "grouped_data = df_unito.groupby('Case')['Prediction'].apply(lambda x: x.mode().iat[0]).reset_index() # restituisce il valore più frequente (moda)\n",
    "grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREAZIONE TABELLA TASK 2 UNENDO LE 6 ANOMALIE\n",
    "grouped_data.rename(columns={'Prediction': 'Task2'}, inplace=True)\n",
    "newww = grouped_data[[\"Case\",\"Task2\"]]\n",
    "newww.loc[newww['Case'].isin([184, 192, 200, 207, 218, 222]), 'Task2'] = -1\n",
    "percorso_file_excel = r'C:\\Users\\umber\\Desktop\\tabella_task2_con_dwt.xlsx'\n",
    "\n",
    "newww.to_excel(percorso_file_excel, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pywt\\_multilevel.py:43: UserWarning: Level value of 12 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.98      0.93     11414\n",
      "           2       0.95      0.74      0.83      5881\n",
      "\n",
      "    accuracy                           0.90     17295\n",
      "   macro avg       0.91      0.86      0.88     17295\n",
      "weighted avg       0.90      0.90      0.89     17295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VALUTAZIONE CON DWT\n",
    "\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_train_finale.csv\")\n",
    "df = df.loc[(df['Case'] >= 106) & (df['Case'] <= 177)]\n",
    "x_test=pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_test_finale.csv\")\n",
    "valori_desiderati = [178, 179, 184, 186, 188, 192, 193, 196, 197, 200, 202, 203, 204, 205, 207, 209, 211, 214, 215, 216, 218, 219, 220 ,221, 222]\n",
    "x_test = x_test[x_test['Case'].isin(valori_desiderati)]\n",
    "test = x_test[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "df = df[[\"Case\",\"Condition\",\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "condition_mapping = {'Fault': 1, 'Anomaly': 2}\n",
    "#0=normal 1=SV e 2=BUBBLE\n",
    "df['Condition'] = df['Condition'].map(condition_mapping)\n",
    "#ALLENAMENTO MODELLO\n",
    "# Creazione di un DataFrame con le features e il target\n",
    "test = x_test[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "colonna = x_test[[\"Case\"]]\n",
    "X=df[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "y = df['Condition']\n",
    "X_dwt = np.concatenate(pywt.wavedec(X, 'db1',level = 12), axis=-1)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_dwt)\n",
    "x_train_sv, x_test_sv, y_train_sv, y_test_sv = train_test_split(X_train_scaled, y, test_size=0.2)\n",
    "model = RandomForestClassifier(max_depth = None, min_samples_leaf = 1, min_samples_split = 2, n_estimators = 200, random_state=42)\n",
    "model.fit(x_train_sv, y_train_sv)\n",
    "predictions = model.predict(x_test_sv)\n",
    "\n",
    "print(classification_report(y_test_sv, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pywt\\_multilevel.py:43: UserWarning: Level value of 12 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     25370\n",
      "           1       0.87      0.63      0.73     11435\n",
      "           2       0.95      0.69      0.80      5711\n",
      "\n",
      "    accuracy                           0.84     42516\n",
      "   macro avg       0.88      0.76      0.80     42516\n",
      "weighted avg       0.85      0.84      0.83     42516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VALUTAZIONE STRADA ALTERNATIVA CON DWT\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_train_finale.csv\")\n",
    "df = df[[\"Case\",\"Condition\",\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "condition_mapping = {'Normal': 0, 'Fault': 1, 'Anomaly': 2}\n",
    "# 0=normal 1=SV e 2=BUBBLE\n",
    "df['Condition'] = df['Condition'].map(condition_mapping)\n",
    "X=df[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "y = df['Condition']\n",
    "X_dwt = np.concatenate(pywt.wavedec(X, 'db1',level = 12), axis=-1)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_dwt)\n",
    "x_train_sv, x_test_sv, y_train_sv, y_test_sv = train_test_split(X_train_scaled, y, test_size=0.2)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(x_train_sv, y_train_sv)\n",
    "predictions = model.predict(x_test_sv)\n",
    "\n",
    "print(classification_report(y_test_sv, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pywt\\_multilevel.py:43: UserWarning: Level value of 12 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pywt\\_multilevel.py:43: UserWarning: Level value of 12 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "C:\\Users\\umber\\AppData\\Local\\Temp\\ipykernel_16564\\458489449.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['Prediction'] = predictions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>178</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case  Prediction\n",
       "0    178           2\n",
       "1    179           0\n",
       "2    180           0\n",
       "3    181           0\n",
       "4    182           0\n",
       "5    183           0\n",
       "6    184           0\n",
       "7    185           0\n",
       "8    186           0\n",
       "9    187           0\n",
       "10   188           0\n",
       "11   189           0\n",
       "12   190           0\n",
       "13   191           0\n",
       "14   192           0\n",
       "15   193           0\n",
       "16   194           0\n",
       "17   195           0\n",
       "18   196           0\n",
       "19   197           0\n",
       "20   198           0\n",
       "21   199           0\n",
       "22   200           0\n",
       "23   201           0\n",
       "24   202           0\n",
       "25   203           0\n",
       "26   204           0\n",
       "27   205           0\n",
       "28   206           0\n",
       "29   207           0\n",
       "30   208           0\n",
       "31   209           0\n",
       "32   210           0\n",
       "33   211           0\n",
       "34   212           0\n",
       "35   213           0\n",
       "36   214           0\n",
       "37   215           0\n",
       "38   216           0\n",
       "39   217           0\n",
       "40   218           0\n",
       "41   219           0\n",
       "42   220           0\n",
       "43   221           0\n",
       "44   222           0\n",
       "45   223           0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALLENAMENTO STRADA ALTERNATIVA CON DWT\n",
    "\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_train_finale.csv\")\n",
    "x_test=pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_test_finale.csv\")\n",
    "test = x_test[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "df = df[[\"Case\",\"Condition\",\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "condition_mapping = {'Normal': 0, 'Fault': 1, 'Anomaly': 2}\n",
    "#0=normal 1=SV e 2=BUBBLE\n",
    "df['Condition'] = df['Condition'].map(condition_mapping)\n",
    "#ALLENAMENTO MODELLO\n",
    "# Creazione di un DataFrame con le features e il target\n",
    "test = x_test[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "colonna = x_test[[\"Case\"]]\n",
    "X=df[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "y = df['Condition']\n",
    "X_dwt = np.concatenate(pywt.wavedec(X, 'db1',level = 12), axis=-1)\n",
    " \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_dwt)\n",
    " \n",
    "X_dwt_test = np.concatenate(pywt.wavedec(test, 'db1',level = 12), axis=-1)\n",
    " \n",
    "scaler = StandardScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_dwt_test)\n",
    " \n",
    "model = RandomForestClassifier(max_depth = None, min_samples_leaf = 1, min_samples_split = 2, n_estimators = 200, random_state=42)\n",
    "model.fit(X_train_scaled, y)\n",
    " \n",
    "# predizioni con dwt\n",
    " \n",
    "predictions = model.predict(X_test_scaled)\n",
    "test['Prediction'] = predictions\n",
    " \n",
    "df_unito = pd.concat([colonna, test], axis=1)\n",
    "grouped_data = df_unito.groupby('Case')['Prediction'].apply(lambda x: x.mode().iat[0]).reset_index() # restituisce il valore più frequente (moda)\n",
    "grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Accuracy = 0.67\n",
      "Decision Tree: Accuracy = 0.90\n",
      "Random Forest: Accuracy = 0.95\n",
      "AdaBoost: Accuracy = 0.67\n",
      "Gradient Boosting: Accuracy = 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM: Accuracy = 0.67\n",
      "K-Nearest Neighbors: Accuracy = 0.78\n",
      "Gaussian Naive Bayes: Accuracy = 0.66\n",
      "Linear Discriminant Analysis: Accuracy = 0.67\n",
      "Quadratic Discriminant Analysis: Accuracy = 0.65\n",
      "Multi-layer Perceptron: Accuracy = 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# diversi modelli senza dwt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "df = pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_train_finale.csv\")\n",
    "df = df.loc[(df['Case'] >= 106) & (df['Case'] <= 177)]\n",
    "x_test=pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_test_finale.csv\")\n",
    "valori_desiderati = [178, 179, 184, 186, 188, 192, 193, 196, 197, 200, 202, 203, 204, 205, 207, 209, 211, 214, 215, 216, 218, 219, 220 ,221, 222]\n",
    "x_test = x_test[x_test['Case'].isin(valori_desiderati)]\n",
    "test = x_test[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "df = df[[\"Case\",\"Condition\",\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "condition_mapping = {'Fault': 1, 'Anomaly': 2}\n",
    "#0=normal 1=SV e 2=BUBBLE\n",
    "df['Condition'] = df['Condition'].map(condition_mapping)\n",
    "#ALLENAMENTO MODELLO\n",
    "# Creazione di un DataFrame con le features e il target\n",
    "test = x_test[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "colonna = x_test[[\"Case\"]]\n",
    "X=df[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "y = df['Condition']\n",
    "# Divisione dei dati in set di training e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definizione dei modelli\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression()),\n",
    "    ('Decision Tree', DecisionTreeClassifier()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('AdaBoost', AdaBoostClassifier()),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier()),\n",
    "    ('Linear SVM', LinearSVC()),\n",
    "    ('K-Nearest Neighbors', KNeighborsClassifier()),\n",
    "    ('Gaussian Naive Bayes', GaussianNB()),\n",
    "    ('Linear Discriminant Analysis', LinearDiscriminantAnalysis()),\n",
    "    ('Quadratic Discriminant Analysis', QuadraticDiscriminantAnalysis()),\n",
    "    ('Multi-layer Perceptron', MLPClassifier())\n",
    "]\n",
    "\n",
    "# Addestramento e valutazione dei modelli\n",
    "for model_name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'{model_name}: Accuracy = {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pywt\\_multilevel.py:43: UserWarning: Level value of 12 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Accuracy = 0.67\n",
      "Decision Tree: Accuracy = 0.83\n",
      "Random Forest: Accuracy = 0.90\n",
      "AdaBoost: Accuracy = 0.67\n",
      "Gradient Boosting: Accuracy = 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM: Accuracy = 0.67\n",
      "K-Nearest Neighbors: Accuracy = 0.77\n",
      "Gaussian Naive Bayes: Accuracy = 0.65\n",
      "Linear Discriminant Analysis: Accuracy = 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic Discriminant Analysis: Accuracy = 0.67\n",
      "Multi-layer Perceptron: Accuracy = 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\umber\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# diversi modelli con dwt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import pywt\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_train_finale.csv\")\n",
    "df = df.loc[(df['Case'] >= 106) & (df['Case'] <= 177)]\n",
    "x_test=pd.read_csv(r\"C:\\Users\\umber\\Desktop\\MANUTENZIONE\\dataset_test_finale.csv\")\n",
    "valori_desiderati = [178, 179, 184, 186, 188, 192, 193, 196, 197, 200, 202, 203, 204, 205, 207, 209, 211, 214, 215, 216, 218, 219, 220 ,221, 222]\n",
    "x_test = x_test[x_test['Case'].isin(valori_desiderati)]\n",
    "test = x_test[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "df = df[[\"Case\",\"Condition\",\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "condition_mapping = {'Fault': 1, 'Anomaly': 2}\n",
    "#0=normal 1=SV e 2=BUBBLE\n",
    "df['Condition'] = df['Condition'].map(condition_mapping)\n",
    "#ALLENAMENTO MODELLO\n",
    "# Creazione di un DataFrame con le features e il target\n",
    "test = x_test[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "colonna = x_test[[\"Case\"]]\n",
    "X=df[[\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]]\n",
    "y = df['Condition']\n",
    "\n",
    "X_dwt = np.concatenate(pywt.wavedec(X, 'db1',level = 12), axis=-1)\n",
    " \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_dwt)\n",
    "\n",
    "# Divisione dei dati in set di training e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definizione dei modelli\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression()),\n",
    "    ('Decision Tree', DecisionTreeClassifier()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('AdaBoost', AdaBoostClassifier()),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier()),\n",
    "    ('Linear SVM', LinearSVC()),\n",
    "    ('K-Nearest Neighbors', KNeighborsClassifier()),\n",
    "    ('Gaussian Naive Bayes', GaussianNB()),\n",
    "    ('Linear Discriminant Analysis', LinearDiscriminantAnalysis()),\n",
    "    ('Quadratic Discriminant Analysis', QuadraticDiscriminantAnalysis()),\n",
    "    ('Multi-layer Perceptron', MLPClassifier())\n",
    "]\n",
    "\n",
    "# Addestramento e valutazione dei modelli\n",
    "for model_name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'{model_name}: Accuracy = {accuracy:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
